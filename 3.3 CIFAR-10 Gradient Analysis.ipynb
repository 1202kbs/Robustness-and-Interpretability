{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from attacks import GM\n",
    "from classifiers import CIFAR_CNN\n",
    "from utils import save, unpickle, pixel_range, preprocess, hist_kde\n",
    "from vae_gans import CIFAR_VAE_GAN\n",
    "\n",
    "datadir = 'CIFAR10_data/cifar-10-batches-py/'\n",
    "batches_train = sorted([datadir + batch for batch in os.listdir(datadir) if 'data_batch' in batch], key=lambda x: int(x[-1]))\n",
    "batch_test = [datadir + 'test_batch']\n",
    "batches = batches_train + batch_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = unpickle(batches[0])\n",
    "data = batch[b'data'].astype(np.float32)\n",
    "cifar = np.transpose(np.reshape(data, [-1, 3, 32, 32]), [0, 2, 3, 1])\n",
    "labels = batch[b'labels']\n",
    "\n",
    "for i in tqdm(range(1, 5)):\n",
    "    batch = unpickle(batches[i])\n",
    "\n",
    "    data = batch[b'data'].astype(np.float32)\n",
    "    cifar = np.concatenate((cifar, np.transpose(np.reshape(data, [-1, 3, 32, 32]), [0, 2, 3, 1])), axis=0)\n",
    "    labels = np.concatenate((labels, batch[b'labels']), axis=0)\n",
    "\n",
    "scaled_cifar = cifar / 127.5 - 1.0\n",
    "\n",
    "test_batch = unpickle(batches[5])\n",
    "cifar_test = np.transpose(np.reshape(test_batch[b'data'], [-1, 3, 32, 32]), [0, 2, 3, 1])\n",
    "scaled_cifar_test = cifar_test / 127.5 - 1.0\n",
    "labels_test = np.array(test_batch[b'labels'])\n",
    "\n",
    "data_train = (scaled_cifar, labels)\n",
    "data_test = (scaled_cifar_test, labels_test)\n",
    "\n",
    "label_map = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Gradient Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "DNN = CIFAR_CNN('tf_logs/exp3/standard/', activation=tf.nn.relu)\n",
    "DNN.load(sess)\n",
    "\n",
    "loss = -tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.stop_gradient(tf.one_hot(DNN.yi, depth=DNN.n_classes)),\n",
    "                                                   logits=DNN.logits)\n",
    "\n",
    "loss_grad = tf.gradients(loss, DNN.X)[0]\n",
    "\n",
    "r1 = preprocess(sess.run(loss_grad, feed_dict={DNN.X: data_test[0][:100]}), q1=0.5, q2=99.5)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "DNN = CIFAR_CNN('tf_logs/exp3/adv/0.02_0.02_40_inf_xent/', activation=tf.nn.relu)\n",
    "DNN.load(sess)\n",
    "\n",
    "loss = -tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.stop_gradient(tf.one_hot(DNN.yi, depth=DNN.n_classes)),\n",
    "                                                   logits=DNN.logits)\n",
    "\n",
    "loss_grad = tf.gradients(loss, DNN.X)[0]\n",
    "\n",
    "r2 = preprocess(sess.run(loss_grad, feed_dict={DNN.X: data_test[0][:100]}), q1=0.5, q2=99.5)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "DNN = CIFAR_CNN('tf_logs/exp3/adv/1.6_2_40_2_xent/', activation=tf.nn.relu)\n",
    "DNN.load(sess)\n",
    "\n",
    "loss = -tf.nn.softmax_cross_entropy_with_logits_v2(labels=tf.stop_gradient(tf.one_hot(DNN.yi, depth=DNN.n_classes)),\n",
    "                                                   logits=DNN.logits)\n",
    "\n",
    "loss_grad = tf.gradients(loss, DNN.X)[0]\n",
    "\n",
    "r3 = preprocess(sess.run(loss_grad, feed_dict={DNN.X: data_test[0][:100]}), q1=0.5, q2=99.5)\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = [2, 10, 28]\n",
    "\n",
    "plt.figure(figsize=(9, 12))\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "\n",
    "    plt.subplot(4, 3, i + 1)\n",
    "    plt.imshow((data_test[0][ind].reshape(32, 32, 3) + 1.0) * 0.5, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(label_map[data_test[1][ind]], fontsize=25)\n",
    "    if i == 0: plt.ylabel('Original', fontsize=25)\n",
    "\n",
    "    plt.subplot(4, 3, 4 + i)\n",
    "    v, _ = pixel_range(r1[ind])\n",
    "    plt.imshow(r1[ind].reshape(32, 32), vmin=v[0], vmax=v[1], cmap='bwr')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0: plt.ylabel('Standard', fontsize=25)\n",
    "\n",
    "    plt.subplot(4, 3, 7 + i)\n",
    "    v, _ = pixel_range(r2[ind])\n",
    "    plt.imshow(r2[ind].reshape(32, 32), vmin=v[0], vmax=v[1], cmap='bwr')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0: plt.ylabel('L-Inf Trained', fontsize=25)\n",
    "\n",
    "    plt.subplot(4, 3, 10 + i)\n",
    "    v, _ = pixel_range(r3[ind])\n",
    "    plt.imshow(r3[ind].reshape(32, 32), vmin=v[0], vmax=v[1], cmap='bwr')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if i == 0: plt.ylabel('L2 Trained', fontsize=25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.04, hspace=0.04)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tf_logs, attack_params):\n",
    "    datasets = []\n",
    "    reconsts = []\n",
    "    suc_inds = []\n",
    "    l2_dists = []\n",
    "\n",
    "    print('Generating Adversarial Attacks')\n",
    "\n",
    "    for name, tf_log in tf_logs:\n",
    "\n",
    "        if not tf_log:\n",
    "            datasets.append((name, data_test[0]))\n",
    "            continue\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        sess = tf.InteractiveSession()\n",
    "\n",
    "        DNN = CIFAR_CNN(tf_log, activation=tf.nn.relu)\n",
    "        DNN.load(sess)\n",
    "\n",
    "        gm = GM(DNN, **attack_params)\n",
    "        datasets.append((name, gm.attack(sess, data_test, batch_size=500)))\n",
    "\n",
    "        sess.close()\n",
    "\n",
    "    print('Generating Projections')\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    vae_gan = CIFAR_VAE_GAN('tf_logs/exp3/vae-gan/')\n",
    "    vae_gan.load(sess)\n",
    "\n",
    "    for name, dataset in datasets:\n",
    "        reconsts.append((name, vae_gan.reconstruct(sess, (dataset, 0))))\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "    print('Removing Unsuccessful Attacks')\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    DNN = CIFAR_CNN('tf_logs/exp3/standard/', activation=tf.nn.relu)\n",
    "    DNN.load(sess)\n",
    "\n",
    "    org_ys = DNN.inference(sess, data_test, batch_size=500)\n",
    "\n",
    "    for name, dataset in datasets:\n",
    "\n",
    "        adv_ys = DNN.inference(sess, (dataset, 0), batch_size=500)\n",
    "\n",
    "        if name == 'Test Data':\n",
    "            suc_inds.append(org_ys == adv_ys)\n",
    "        else:\n",
    "            suc_inds.append(org_ys != adv_ys)\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "    print('Calculating L2 Distances')\n",
    "\n",
    "    for i, ((name, dataset), (_, reconst)) in enumerate(zip(datasets, reconsts)):\n",
    "        l2_dist = np.sqrt(np.sum(np.square(dataset[suc_inds[i]] - reconst[suc_inds[i]]), axis=(1, 2, 3)))\n",
    "        l2_dists.append((name, l2_dist))\n",
    "\n",
    "    return datasets, reconsts, l2_dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_logs1 = [('Test Data', None),\n",
    "            ('Standard', 'tf_logs/exp3/standard/'),\n",
    "            ('L2 0.1 XEnt', 'tf_logs/exp3/adv/0.1_2_40_2_xent/'),\n",
    "            ('L2 0.4 XEnt', 'tf_logs/exp3/adv/0.4_2_40_2_xent/'),\n",
    "            ('L2 1.6 XEnt', 'tf_logs/exp3/adv/1.6_2_40_2_xent/')\n",
    "            ]\n",
    "\n",
    "tf_logs2 = [('Test Data', None),\n",
    "            ('Standard', 'tf_logs/exp3/standard/'),\n",
    "            ('L2 0.1 CW', 'tf_logs/exp3/adv/0.1_2_40_2_cw/'),\n",
    "            ('L2 0.4 CW', 'tf_logs/exp3/adv/0.4_2_40_2_cw/'),\n",
    "            ('L2 1.6 CW', 'tf_logs/exp3/adv/1.6_2_40_2_cw/')\n",
    "            ]\n",
    "\n",
    "tf_logs3 = [('Test Data', None),\n",
    "            ('Standard', 'tf_logs/exp3/standard/'),\n",
    "            ('L-Inf 0.005 XEnt', 'tf_logs/exp3/adv/0.005_0.02_40_inf_xent/'),\n",
    "            ('L-Inf 0.01 XEnt', 'tf_logs/exp3/adv/0.01_0.02_40_inf_xent/'),\n",
    "            ('L-Inf 0.02 XEnt', 'tf_logs/exp3/adv/0.02_0.02_40_inf_xent/'),\n",
    "            ]\n",
    "\n",
    "tf_logs4 = [('Test Data', None),\n",
    "            ('Standard', 'tf_logs/exp3/standard/'),\n",
    "            ('L-Inf 0.005 CW', 'tf_logs/exp3/adv/0.005_0.02_40_inf_cw/'),\n",
    "            ('L-Inf 0.01 CW', 'tf_logs/exp3/adv/0.01_0.02_40_inf_cw/'),\n",
    "            ('L-Inf 0.02 CW', 'tf_logs/exp3/adv/0.02_0.02_40_inf_cw/'),\n",
    "            ]\n",
    "\n",
    "# attack_params = {'eps': 12, 'step_size': 2, 'n_steps': 40, 'norm': '2', 'loss_type': 'xent'}\n",
    "attack_params = {'eps': 12, 'step_size': 2, 'n_steps': 40, 'norm': '2', 'loss_type': 'cw'}\n",
    "\n",
    "ress = []\n",
    "\n",
    "for tf_logs in [tf_logs1, tf_logs2, tf_logs3, tf_logs4]:\n",
    "    ress.append(evaluate(tf_logs, attack_params))\n",
    "\n",
    "save(ress, 'results/gradient/exp3/results_{}.pickle'.format(attack_params['loss_type']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress = unpickle('results/gradient/exp3/results_xent.pickle')\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, res in enumerate(ress):\n",
    "\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "\n",
    "    for j, (name, l2_dist) in enumerate(res[2]):\n",
    "\n",
    "        if name == 'Test Data':\n",
    "            xmin = np.min(l2_dist)\n",
    "            xmax = np.max(l2_dist)\n",
    "\n",
    "        xs, ys = hist_kde((l2_dist - xmin) / (xmax - xmin), [0.0, 1.0])\n",
    "        plt.plot(xs, ys, label=name)\n",
    "\n",
    "    plt.xlim([0.0, 0.2])\n",
    "    plt.ylim([0, 30])\n",
    "\n",
    "    plt.xticks(np.arange(0, 0.21, 0.05))\n",
    "\n",
    "    plt.xlabel('L2 Distance to Manifold', fontsize=12)\n",
    "    plt.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress = unpickle('results/gradient/exp3/results_cw.pickle')\n",
    "\n",
    "plt.figure(figsize=(16, 3))\n",
    "\n",
    "for i, res in enumerate(ress):\n",
    "\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "\n",
    "    for j, (name, l2_dist) in enumerate(res[2]):\n",
    "\n",
    "        if name == 'Test Data':\n",
    "            xmin = np.min(l2_dist)\n",
    "            xmax = np.max(l2_dist)\n",
    "\n",
    "        xs, ys = hist_kde((l2_dist - xmin) / (xmax - xmin), [0.0, 1.0])\n",
    "        plt.plot(xs, ys, label=name)\n",
    "\n",
    "    plt.xlim([0.0, 0.2])\n",
    "    plt.ylim([0, 30])\n",
    "\n",
    "    plt.xticks(np.arange(0, 0.21, 0.05))\n",
    "\n",
    "    plt.xlabel('L2 Distance to Manifold', fontsize=12)\n",
    "    plt.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Attack Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ress = unpickle('results/gradient/exp3/results_xent.pickle')\n",
    "# ress = unpickle('results/gradient/exp3/results_cw.pickle')\n",
    "\n",
    "i = 1\n",
    "\n",
    "plt.figure(figsize=(3 * len(ress[0][0]), 6))\n",
    "\n",
    "for j, (name, x) in enumerate(ress[0][0]):\n",
    "\n",
    "    plt.subplot(2, len(ress[0][0]), j + 1)\n",
    "    plt.imshow((x[i].reshape(32, 32, 3) + 1.0) * 0.5, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Original' if name == 'Test Data' else name, fontsize=20, pad=10)\n",
    "\n",
    "    if j == 0:\n",
    "        plt.ylabel('CIFAR-10', fontsize=20, labelpad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=-0.15, hspace=0.03)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
